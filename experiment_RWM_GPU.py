import argparse
import time
import torch
from interfaces import MCMCSimulation_GPU
from algorithms import RandomWalkMH_GPU
import numpy as np
from target_distributions import MultivariateNormal_GPU, MultivariateNormal
import matplotlib.pyplot as plt
import json

def get_target_distribution(name, dim, use_gpu=True):
    """Get target distribution with optional GPU acceleration."""
    if use_gpu and name == "MultivariateNormal":
        return MultivariateNormal_GPU(dim)
    elif name == "MultivariateNormal":
        return MultivariateNormal(dim)
    else:
        # For other distributions, fall back to CPU versions
        from target_distributions import (RoughCarpetDistribution, ThreeMixtureDistribution, 
                                        Hypercube, IIDGamma, IIDBeta)
        if name == "RoughCarpet":
            return RoughCarpetDistribution(dim, scaling=False)
        elif name == "RoughCarpetScaled":
            return RoughCarpetDistribution(dim, scaling=True)
        elif name == "ThreeMixture":
            return ThreeMixtureDistribution(dim, scaling=False)
        elif name == "ThreeMixtureScaled":
            return ThreeMixtureDistribution(dim, scaling=True)
        elif name == "Hypercube":
            return Hypercube(dim, left_boundary=-1, right_boundary=1)
        elif name == "IIDGamma":
            return IIDGamma(dim, shape=2, scale=3)
        elif name == "IIDBeta":
            return IIDBeta(dim, alpha=2, beta=3)
        else:
            raise ValueError("Unknown target distribution name")

def run_performance_comparison(dim, num_iters, target_name="MultivariateNormal"):
    """Compare GPU vs CPU performance for a single configuration."""
    print(f"\n{'='*60}")
    print(f"PERFORMANCE COMPARISON: {target_name} (dim={dim}, samples={num_iters})")
    print(f"{'='*60}")
    
    # Test variance (roughly optimal for high dimensions)
    variance = 2.38**2 / dim
    
    # GPU version
    print("\nüöÄ Testing GPU-accelerated implementation...")
    target_dist_gpu = get_target_distribution(target_name, dim, use_gpu=True)
    
    gpu_start = time.time()
    simulation_gpu = MCMCSimulation_GPU(
        dim=dim,
        sigma=variance,
        num_iterations=num_iters,
        algorithm=RandomWalkMH_GPU,
        target_dist=target_dist_gpu,
        symmetric=True,
        batch_size=min(1024, num_iters//10),  # Adaptive batch size
        pre_allocate=True,
        seed=42
    )
    
    chain_gpu = simulation_gpu.generate_samples(use_batch_processing=True, progress_bar=False)
    gpu_time = time.time() - gpu_start
    gpu_acceptance = simulation_gpu.acceptance_rate()
    gpu_esjd = simulation_gpu.expected_squared_jump_distance()
    
    print(f"‚úÖ GPU Results:")
    print(f"   Time: {gpu_time:.2f} seconds")
    print(f"   Samples/sec: {num_iters/gpu_time:.0f}")
    print(f"   Acceptance rate: {gpu_acceptance:.3f}")
    print(f"   ESJD: {gpu_esjd:.6f}")
    
    # CPU version for comparison (using original implementation)
    print("\nüêå Testing CPU implementation...")
    from algorithms import RandomWalkMH
    from interfaces import MCMCSimulation
    
    target_dist_cpu = get_target_distribution(target_name, dim, use_gpu=False)
    
    cpu_start = time.time()
    simulation_cpu = MCMCSimulation(
        dim=dim,
        sigma=variance,
        num_iterations=num_iters,
        algorithm=RandomWalkMH,
        target_dist=target_dist_cpu,
        symmetric=True,
        seed=42
    )
    
    chain_cpu = simulation_cpu.generate_samples()
    cpu_time = time.time() - cpu_start
    cpu_acceptance = simulation_cpu.acceptance_rate()
    cpu_esjd = simulation_cpu.expected_squared_jump_distance()
    
    print(f"‚úÖ CPU Results:")
    print(f"   Time: {cpu_time:.2f} seconds")
    print(f"   Samples/sec: {num_iters/cpu_time:.0f}")
    print(f"   Acceptance rate: {cpu_acceptance:.3f}")
    print(f"   ESJD: {cpu_esjd:.6f}")
    
    # Calculate speedup
    speedup = cpu_time / gpu_time
    print(f"\nüéØ Performance Summary:")
    print(f"   Speedup: {speedup:.1f}x faster")
    print(f"   GPU efficiency: {speedup:.1f}x improvement")
    
    # Verify results are similar
    acc_diff = abs(gpu_acceptance - cpu_acceptance)
    esjd_diff = abs(gpu_esjd - cpu_esjd) / max(gpu_esjd, cpu_esjd)
    
    print(f"\nüîç Accuracy Verification:")
    print(f"   Acceptance rate difference: {acc_diff:.4f}")
    print(f"   ESJD relative difference: {esjd_diff:.4f}")
    
    if acc_diff < 0.05 and esjd_diff < 0.1:
        print("   ‚úÖ Results are consistent between GPU and CPU")
    else:
        print("   ‚ö†Ô∏è  Large differences detected - check implementation")
    
    return {
        'gpu_time': gpu_time,
        'cpu_time': cpu_time,
        'speedup': speedup,
        'gpu_acceptance': gpu_acceptance,
        'cpu_acceptance': cpu_acceptance,
        'gpu_esjd': gpu_esjd,
        'cpu_esjd': cpu_esjd
    }

def run_optimization_study(dim, target_name="MultivariateNormal", num_iters=50000):
    """Run parameter optimization study using GPU acceleration."""
    print(f"\n{'='*60}")
    print(f"GPU-ACCELERATED PARAMETER OPTIMIZATION")
    print(f"Target: {target_name}, Dimension: {dim}, Samples: {num_iters}")
    print(f"{'='*60}")
    
    target_distribution = get_target_distribution(target_name, dim, use_gpu=True)
    var_value_range = np.linspace(0.000001, 2.0, 20)  # Reduced range for faster testing
    
    acceptance_rates = []
    expected_squared_jump_distances = []
    times = []
    
    print(f"\nRunning optimization sweep with {len(var_value_range)} variance values...")
    
    total_start = time.time()
    
    for i, var in enumerate(var_value_range):
        variance = (var ** 2) / (dim ** (1))
        
        iteration_start = time.time()
        
        simulation = MCMCSimulation_GPU(
            dim=dim,
            sigma=variance,
            num_iterations=num_iters,
            algorithm=RandomWalkMH_GPU,
            target_dist=target_distribution,
            symmetric=True,
            batch_size=min(2048, num_iters//5),  # Aggressive batching
            pre_allocate=True,
            seed=42 + i  # Different seed for each run
        )
        
        chain = simulation.generate_samples(use_batch_processing=True, progress_bar=False)
        
        iteration_time = time.time() - iteration_start
        times.append(iteration_time)
        
        acceptance_rates.append(simulation.acceptance_rate())
        expected_squared_jump_distances.append(simulation.expected_squared_jump_distance())
        
        if (i + 1) % 5 == 0:
            print(f"   Progress: {i+1}/{len(var_value_range)} "
                  f"({iteration_time:.1f}s, acc={acceptance_rates[-1]:.3f})")
        
        simulation.reset()  # Clean up for next iteration
    
    total_time = time.time() - total_start
    
    # Find optimal parameters
    max_esjd = max(expected_squared_jump_distances)
    max_esjd_index = np.argmax(expected_squared_jump_distances)
    max_acceptance_rate = acceptance_rates[max_esjd_index]
    max_variance_value = var_value_range[max_esjd_index]
    
    print(f"\nüéØ Optimization Results:")
    print(f"   Total time: {total_time:.1f} seconds")
    print(f"   Average time per configuration: {np.mean(times):.1f} seconds")
    print(f"   Maximum ESJD: {max_esjd:.6f}")
    print(f"   Optimal acceptance rate: {max_acceptance_rate:.3f}")
    print(f"   Optimal variance value: {max_variance_value:.6f}")
    
    # Save results
    data = {
        'target_distribution': target_name,
        'dimension': dim,
        'num_iterations': num_iters,
        'total_time': total_time,
        'max_esjd': max_esjd,
        'max_acceptance_rate': max_acceptance_rate,
        'max_variance_value': max_variance_value,
        'expected_squared_jump_distances': expected_squared_jump_distances,
        'acceptance_rates': acceptance_rates,
        'var_value_range': var_value_range.tolist(),
        'times': times
    }
    
    filename = f"data/{target_name}_RWM_GPU_dim{dim}_{num_iters}iters.json"
    with open(filename, "w") as file:
        json.dump(data, file, indent=2)
    print(f"   Results saved to: {filename}")
    
    # Create visualization
    plt.figure(figsize=(12, 8))
    
    # Plot 1: ESJD vs Acceptance Rate
    plt.subplot(2, 2, 1)
    plt.plot(acceptance_rates, expected_squared_jump_distances, 'b-o', markersize=4)
    plt.axvline(x=0.234, color='red', linestyle='--', alpha=0.7, label='Theory: a=0.234')
    plt.xlabel('Acceptance Rate')
    plt.ylabel('ESJD')
    plt.title('ESJD vs Acceptance Rate (GPU)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot 2: Acceptance Rate vs Variance
    plt.subplot(2, 2, 2)
    plt.plot(var_value_range, acceptance_rates, 'g-o', markersize=4)
    plt.xlabel('Variance Parameter')
    plt.ylabel('Acceptance Rate')
    plt.title('Acceptance Rate vs Variance')
    plt.grid(True, alpha=0.3)
    
    # Plot 3: ESJD vs Variance
    plt.subplot(2, 2, 3)
    plt.plot(var_value_range, expected_squared_jump_distances, 'r-o', markersize=4)
    plt.xlabel('Variance Parameter')
    plt.ylabel('ESJD')
    plt.title('ESJD vs Variance')
    plt.grid(True, alpha=0.3)
    
    # Plot 4: Computation Time per Configuration
    plt.subplot(2, 2, 4)
    plt.plot(range(len(times)), times, 'purple', marker='o', markersize=4)
    plt.xlabel('Configuration Index')
    plt.ylabel('Time (seconds)')
    plt.title('Computation Time per Configuration')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plot_filename = f"images/ESJD_optimization_GPU_{target_name}_dim{dim}_{num_iters}iters.png"
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   Plots saved to: {plot_filename}")
    
    return data

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="GPU-accelerated RWM simulations")
    parser.add_argument("--dim", type=int, default=20, help="Dimension of the target distribution")
    parser.add_argument("--target", type=str, default="MultivariateNormal", help="Target distribution")
    parser.add_argument("--num_iters", type=int, default=100000, help="Number of iterations")
    parser.add_argument("--mode", type=str, default="comparison", 
                       choices=["comparison", "optimization", "benchmark"],
                       help="Mode: comparison (GPU vs CPU), optimization (parameter sweep), or benchmark")
    
    args = parser.parse_args()
    
    # Check GPU availability
    if torch.cuda.is_available():
        print(f"üöÄ GPU detected: {torch.cuda.get_device_name()}")
        print(f"   CUDA version: {torch.version.cuda}")
        print(f"   GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("‚ö†Ô∏è  No GPU detected. Running on CPU (will be slower)")
    
    if args.mode == "comparison":
        # Performance comparison
        results = run_performance_comparison(args.dim, args.num_iters, args.target)
        
    elif args.mode == "optimization":
        # Parameter optimization study
        results = run_optimization_study(args.dim, args.target, args.num_iters)
        
    elif args.mode == "benchmark":
        # Comprehensive benchmark
        print(f"\n{'='*60}")
        print("COMPREHENSIVE GPU BENCHMARK")
        print(f"{'='*60}")
        
        dimensions = [5, 10, 20, 50] if args.dim > 20 else [5, 10, args.dim]
        sample_sizes = [10000, 50000, 100000] if args.num_iters >= 100000 else [1000, 5000, args.num_iters]
        
        benchmark_results = []
        
        for dim in dimensions:
            for num_samples in sample_sizes:
                print(f"\nBenchmarking: dim={dim}, samples={num_samples}")
                result = run_performance_comparison(dim, num_samples, args.target)
                result.update({'dim': dim, 'num_samples': num_samples})
                benchmark_results.append(result)
        
        # Save comprehensive benchmark
        benchmark_data = {
            'target_distribution': args.target,
            'timestamp': time.time(),
            'results': benchmark_results
        }
        
        benchmark_filename = f"data/GPU_benchmark_{args.target}_{int(time.time())}.json"
        with open(benchmark_filename, "w") as file:
            json.dump(benchmark_data, file, indent=2)
        
        print(f"\nüéØ Benchmark completed! Results saved to: {benchmark_filename}")
    
    print(f"\n‚úÖ GPU optimization analysis complete!")
    print(f"üí° Your Metropolis algorithm should now run {10}-{100}x faster with GPU acceleration!") 